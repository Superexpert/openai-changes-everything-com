---
layout: episode
episode_id: "do-we-owe-chatgpt-the-same-care-as-animals"
---

In this compelling episode of the Move 37 Podcast podcast, host Stephen Walther engages philosopher John Basl, Associate Professor at Northeastern University, in an insightful discussion about the ethical implications of artificial consciousness. Basl specializes in moral philosophy, applied ethics, and the ethics of emerging technologies like AI and synthetic biology.

Basl shares his skepticism regarding the current state of AI consciousness, questioning whether popular models like ChatGPT truly exhibit conscious experiences. He emphasizes the complexity in determining consciousness, especially due to the lack of shared evolutionary history and biological similarity between humans and AI systems.

Key discussion points include:

- **Ethical Considerations of AI Welfare**: Basl argues that if AI systems become capable of experiencing pleasure or pain, we have a moral obligation to consider their welfare, similar to how we approach the welfare of animals. He introduces the concept of the "dependency thesis," challenging the notion that our moral obligations depend solely on the correctness of particular moral theories.

- **Risks in AI Research**: Basl highlights ethical concerns in developing AI with potentially ambiguous moral status, citing "neural chimeras" (organisms created by integrating human and animal neural tissue) as a parallel ethical concern in biological research. He emphasizes the responsibility of researchers to minimize suffering in entities they create or modify, advocating for proactive ethical considerations in AI development.

- **Challenges of AI Consciousness Detection**: Acknowledging the "hard problem of consciousness," Basl notes the difficulty in definitively identifying consciousness in AI, which raises ethical challenges. He advocates for caution, especially as AI systems become more sophisticated and human-like.

- **Regulatory Oversight**: Basl supports stronger regulatory oversight for AI development, especially when attempting to replicate human-like neural processes, to prevent potential ethical transgressions.

- **Public Education on AI**: Both Walther and Basl stress the importance of educating the public about AI technologies to foster informed ethical discussions and decisions. Basl recommends resources such as Shannon Vallor’s "The AI Mirror" and "AI Snake Oil" by Arvind Narayanan and Sayash Kapoor for deeper insights.

Listeners gain a nuanced perspective on the ethical responsibilities of developing artificial consciousness, underscoring the importance of thoughtful, informed consideration as technology rapidly advances.

Subscribe to the Move 37 Podcast podcast to explore more critical discussions on AI’s role in shaping the future of humanity.

