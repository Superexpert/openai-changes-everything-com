---
layout: episode
episode_id: "practical-rai-for-companies"
---


In this episode of the “OpenAI Changes Everything” podcast, host Stephen Walther explores the complexities of implementing Responsible AI principles across different cultures. He speaks with Pouria Akbari, a PhD researcher specializing in responsible data science, about how the interpretation of concepts like “fairness” varies significantly based on cultural context.

Pouria highlights real-world examples—such as using facial recognition in swimming pools in Islamic versus Western countries—to illustrate how fairness can mean different things in different societies. He emphasizes that responsible AI principles aren’t absolute and that a universal definition is challenging due to cultural relativity. They discuss practical challenges organizations face when operationalizing these principles, emphasizing capabilities like bias remediation, common good, explainability, and harmlessness.

The conversation addresses the difficulty companies face balancing profitability with responsible practices. Pouria argues that businesses must adopt Responsible AI proactively to avoid future pitfalls, like public backlash from AI-related scandals.

Finally, Pouria recommends resources for further learning, including books such as AI Ethics by Mark Coeckelbergh and Human Compatible, along with websites like the AI Incidents Database, encouraging product managers to understand Responsible AI as essential for sustainable innovation rather than a barrier to business objectives.